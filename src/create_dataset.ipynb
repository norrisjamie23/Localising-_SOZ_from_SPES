{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create SPES response dataset\n",
    "This notebook creates a dataset suitable for subsequent PyTorch analyses. SPES responses are extracted for each patient, and then NumPy files are created.\n",
    "\n",
    "### Extract mean and standard deviation for each unique stimulation/response pair, across all patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_dataset import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "mne.set_log_level('WARNING')\n",
    "\n",
    "# Set root directory for BIDS dataset\n",
    "bids_root = '/Users/jamienorris/ds004080'\n",
    "\n",
    "# Define the BIDSDataLoader and StimulationDataProcessor\n",
    "bids_loader = BIDSDataLoader(bids_root=bids_root)\n",
    "subjects = bids_loader.load_subjects()\n",
    "stim_processor = StimulationDataProcessor(tmin=0.009, tmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 20/36 [10:16<06:27, 24.24s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccepAgeUMCU47 538 76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 31/36 [15:18<02:56, 35.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccepAgeUMCU61 560 470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 32/36 [15:46<02:13, 33.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ccepAgeUMCU62 629 479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [17:28<00:00, 29.13s/it]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty list to store the response data\n",
    "response_df = []\n",
    "\n",
    "# Iterate over each subject and process the data, adding to the list\n",
    "for subject in tqdm(subjects):\n",
    "\n",
    "    # Load the session data\n",
    "    session_data = bids_loader.load_session_data(subject)\n",
    "\n",
    "    # Create an empty list to store the response data for each run for current patient\n",
    "    patient_response_df = []\n",
    "    \n",
    "    # Iterate over each run\n",
    "    for run in session_data['runs']:\n",
    "\n",
    "        # Load the run data\n",
    "        run_data = bids_loader.load_run_data(subject, run)\n",
    "\n",
    "        # Process the run data and append to the list\n",
    "        patient_response_df.append(stim_processor.process_run_data(run_data['eeg'], run_data['events_df'], run_data['channels_df'], subject))\n",
    "    \n",
    "    # Concatenate the response data across runs\n",
    "    patient_response_df = pd.concat(patient_response_df)\n",
    "    \n",
    "    # Group by recording, stim_1, stim_2 and apply the combine_stats function\n",
    "    grouped = patient_response_df.groupby(['recording', 'stim_1', 'stim_2'])\n",
    "\n",
    "    # Combine data across runs\n",
    "    patient_response_df = pd.concat([pd.concat(combine_stats(group)) for _, group in grouped])\n",
    "\n",
    "    # Add the subject to the dataframe\n",
    "    response_df.append(patient_response_df)\n",
    "\n",
    "# Concatenate the response data across subjects\n",
    "response_df = pd.concat(response_df)\n",
    "# response_df = response_df.astype({col: 'float32' for col in response_df.columns if response_df[col].dtype == 'float64'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the patients listed above are those for whom some trials are outside of the time frame. The first number is the number of trials, the second is the number of trials within the time frame of the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save or load the dataframe (worth saving to save your time in future!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df_filepath = '../response_df.csv'\n",
    "response_df.to_csv(response_df_filepath)\n",
    "# response_df = pd.read_csv(response_df_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset(s)\n",
    "First, create the relevant folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ../data/mean\n",
    "!mkdir -p ../data/std\n",
    "!mkdir -p ../data/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise DatasetCreator with the dataframe created above, then process each patient, creating the relevant files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [02:50<00:00,  4.74s/it]\n"
     ]
    }
   ],
   "source": [
    "datasetcreator = DatasetCreator(response_df)\n",
    "\n",
    "# Assuming you have loaded run_data using BIDSDataLoader\n",
    "for subject in tqdm(subjects):\n",
    "    session_data = bids_loader.load_session_data(subject)\n",
    "    datasetcreator.process_for_analysis(subject, session_data['electrodes_tsv'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
